---
layout:     post
title:      文本聚类
subtitle:   聚类
date:       2017-02-06
author:     BY
header-img: img/post-bg-re-vs-ng2.jpg
catalog: true
tags:
    - Blog
---

### others

```
词向量平均，对效果有略微提升。
word2vec glove fasttext

模型融合
不同模型融合与不同checkpoint 融合。

胶囊网络


```

### 论文作者消歧

```
0. K-way spectral clustering method

1.Name Disambiguation Using Atomic Clusters.
a.find atom cluster; high precious, low recall;
b.integrate the atomic clusters into Hierarchical clustering and Kmeans.

2.Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop.
融合：
a. 特征构建法
聚类（DBSCAN）与分类

b. 图关联法
图团体检测

step:
1. doc embedding: word2vec + idf

2. 降维 : triple loss（源自15年facenet） + ae
采样方式，正采样1：4，采样两次
训练样本164w
训练速度很快
loss = 0.25
test accuracy before 0.7586815201689077
test accuracy after 0.9009264918324258
test AUC before 0.7025700386226873
test AUC after 0.905988236996677
val AUC 0.905988236996677
test accuracy before 0.7586815201689077
test accuracy after 0.9009264918324258
test AUC before 0.7025700386226873
test AUC after 0.905988236996677
val AUC 0.905988236996677

阈值矫正

特征emb拼接：
内容+作者+关键词
loss 下降很多，收敛更稳定
loss = 0.20
test accuracy before 0.7586537393043672
test accuracy after 0.921199577730859
test AUC before 0.7006389990424384
test AUC after 0.9259890989445759
val AUC 0.9259890989445759

问题：
过拟合

3. 负采样优化
Semi-hard Negative Samples 2015
多采样负样本，发现收益并不大，也试过先召回一部分和答案相似的样本，再做 reranking，或者在 DE 前或者后加别的 ranking 来进一步缩小范围，也是收效甚微
http://www.shuang0420.com/2018/03/17/%E6%89%AF%E6%89%AF%20Semi-hard%20Negative%20Samples/

简单来说就是选择难度适当的错误回复（semi-hard negative samples）作为负样本

但选择 hardest negatives 在实际当中容易导致在训练最开始的时候就陷入局部最优，所以实际会选择 semi-hard negatives

test accuracy before 0.7586537393043672
test accuracy after 0.8612345816201801
test AUC before 0.7006389990424384
test AUC after 0.8745507406890483
val AUC 0.8745507406890483

2019 bag of negtive


4. 聚类：DBSCAN + hac
聚类质量指标
1. 轮廓系数
2. 调整兰德系数
3. 互信息
4. Calinski-Harabasz

# 提交结果
last_emb_layer + emb_150 + kmeans + 随机采样
（sse 巨大）
1. 100类聚类 0.2
2. 20类聚类 0.24
3. 10类聚类 0.26

todo:
norm_layer + + emb_150 + kmeans + 半监督采样
（sse 降下来了）
4. 10类聚类  0.334
5. 5类聚类  0.3
6. 8类聚类  0.335
7 7类
10：300emb + train  0.328
11:  8类 300emb + train  + 半监督 0.336
12：10类   0.340
13  


_1： 10类 300emb + train  + 半监督（20次）0.366

## 总结与不足
不足
1.没有baseline， tf-idf 特征+降维+聚类，没有去做
2.词向量只用了glove，bert，erine没有试
3.stack ae 没有用weight-tied技巧；
4.评测部分没有实现
5.模型融合没有去做

收获：
1.自编码器的特征提取，有降维效果；
2.半监督数据增强，略微对ae训练有帮助

最终排名26/553.
```

